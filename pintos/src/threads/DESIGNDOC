			+--------------------+
			|        CS 153      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Jonathan Candelaria <jcand003@ucr.edu> <861062229>
Selik Samai <santo003@ucr.edu> <861033991>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.
	- Extra credit advanced scheduler not attempted.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.
	-N/A

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

static struct list sleeping_threads;
This was added in timer.c and keeps track of the sleeping threads

int64_t ticks;
This was added to thread.h in struct thread.
If the thread is currently sleeping the tick will indicate when the thread is needed and ready to be unblocked.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

void timer_sleep (int64_t ticks)
We use the global variable to calculate the tick value for the thread.
The thread is then added to the sleep list. 
We implemented it in such a way that the thread is added to the sleep list in a sorted order. 
The thread is blocked.

static void timer_interrupt (struct intr_frame *args UNUSED)
We used a for loop to iterate the begging to end of the sleeping_threads list.
We compare the threads tick value and if it is less thean 0 we unblock and remove it from the list. 
We then increment the tick value cand call thread_tick().	

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

Because we made our sleepint_threads list in sorted order we do not spend any more timme in the timer interrupt handler than is necessary.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
	struct list slp_list:
	enum interrupt prev_level:this is for turning interrupts off
		so that we can add a thread to our sleep list 
	
	struct lock *wait:this is the lock that a waiting thread is 
		waiting on
	
	struct list lock_donations: This is a list of threads requiring
		donation. 
	struct add_donation:this can be added to another threads donation
		
>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)
	for priority donation, we use a priority queue. The thread with the
	highest priority is run, while lower priority threads wait. This ensures
	that we are executing tasks that are most important.

	Priority 1		Priority 2		Priority 3
	_________		_________		_________
	|  A	|---------->>	|  B	|--------->>	|  C	|
	|_______|		|_______|		|_______|
	
	Here we have 3 threads, ecah with different priority. The thread
	with the highest priority is Priority 3, lowest is Priority 1. We 
	still need to use locks to make sure other threads aren't taking up
	resources. So if P3 needs a resource it acquires a lock (no other 
	thread has access to a locked resource). So if threads A and C use the 
	same resource but thread A has the lock, thread C can't run. Donation		will allow thread A to then have the same priority of thread C. So now
	thread A can run before thread B and upon completion, will release the
	lock for thread C, then thread B will run. So, to implement this, we 
	need to notate which thread has the lock in addition to our priority 
	queue 

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
	based off of our priority. We assigned specific values (0-63) 
	and each thread is assigned a priority and placed in a priority
	queue.When we are running, we are sure that the first entry in the 
	queue is woken first. We simply have a list that inserts in the 
	manner conducive to produce an O(1) pop for waking up the thread
	if the highest priority thread is not able to acquire the lock 
	because another thread has it, then we would use priority donation
	on the thread with the lock(thread with locks priority == waiting 
	thread 	priority). This will allow for the lock to be released, 
	we of course would need to allow for the thread that received the 
	donation to run and release the lock so that our waiting thread can run
	and execute.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
	lock_acquire() first disables interrupts 
	if(lock is not held){
		this thread needs to receive current waiting threads priority
	}
	if(lock held w/ low priority){
		current thread adds self to donation list 
	}
	if(lock held w/high priority){
		
	}	
>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
	*lock holder == NULL
	*donation is obsolete once lock is released 
	*find highest priority thread after refreshing current threads priority
	* a new thread acquires lock 
	* thread with lock goes in ready queue
	* check if need to yield
---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?
	When interrupts are turned off, we can encounter a potential race 		condition in where a thread priority is being updated and threads 
	are trying to set the same priority to multiple threads.
---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
	Our design is based heavily on the linked list style and having to 
	implement the priority queue, this allowed for all popping operations
	to be O(1). Since we knew we would have to disable interrupts when 
	organizing our list, we wanted to make sure we minimized issues with it.
	Based off the priority of the inserted thread determines it's location 		in the list.So if the thread has a high priority, it'll be inserted 
	in front of list. We want to minimize the length of time interrupts
	are off. There are implementations where one could just insert into 
	the list unsorted and only pop the list by iterating through but
	this seems wasteful. 
			  ADVANCED SCHEDULER
			    (If Attempted)
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
